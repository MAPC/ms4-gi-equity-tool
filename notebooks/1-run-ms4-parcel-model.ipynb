{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols \n",
    "from rasterstats import zonal_stats\n",
    "import rasterio\n",
    "import contextily as cx\n",
    "from rasterio.plot import show\n",
    "#import osmnx as ox\n",
    "from affine import Affine\n",
    "import rioxarray as rx\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from shapely.ops import unary_union\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import fiona\n",
    "\n",
    "#see all columns in tables\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in municipal and regional boundaries...\n",
      "Reading in land parcel database data...\n",
      "Reading in additional data layers...\n",
      "Wetlands...\n",
      "Watersheds...\n",
      "Wellhead protection areas...\n",
      "Activity use limitation areas...\n",
      "ParkServe data...\n"
     ]
    }
   ],
   "source": [
    "#import parcel model function \n",
    "from src.features.parcel_model import parcel_ms4_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on Wayland at 2023-07-05 16:29:34...\n",
      "Starting on Norwell at 2023-07-05 16:37:11...\n",
      "Starting on Lynnfield at 2023-07-05 16:40:12...\n",
      "Starting on Ipswich at 2023-07-05 16:42:28...\n",
      "Starting on Stow at 2023-07-05 16:50:07...\n",
      "Starting on Cohasset at 2023-07-05 16:52:34...\n",
      "Starting on Lincoln at 2023-07-05 16:54:58...\n",
      "Starting on Acton at 2023-07-05 16:56:39...\n",
      "Starting on Waltham at 2023-07-05 17:00:43...\n",
      "Starting on Foxborough at 2023-07-05 17:07:10...\n",
      "Starting on Sudbury at 2023-07-05 17:10:30...\n",
      "Starting on Beverly at 2023-07-05 17:14:39...\n",
      "Starting on Hopkinton at 2023-07-05 17:22:05...\n",
      "Starting on Randolph at 2023-07-05 17:25:42...\n",
      "Starting on Maynard at 2023-07-05 17:31:14...\n",
      "Starting on Rockland at 2023-07-05 17:33:05...\n",
      "Starting on Woburn at 2023-07-05 17:35:44...\n",
      "Starting on North Reading at 2023-07-05 17:41:34...\n",
      "Starting on Milton at 2023-07-05 17:44:26...\n",
      "Starting on Newton at 2023-07-05 17:51:02...\n",
      "Starting on Peabody at 2023-07-05 18:07:00...\n",
      "Starting on Danvers at 2023-07-05 18:13:41...\n",
      "Starting on Braintree at 2023-07-05 18:19:14...\n",
      "Starting on Franklin at 2023-07-05 18:23:51...\n",
      "Starting on Rockport at 2023-07-05 18:29:38...\n",
      "Starting on Boxborough at 2023-07-05 18:31:52...\n",
      "Starting on Watertown at 2023-07-05 18:33:06...\n",
      "Starting on Sherborn at 2023-07-05 18:36:51...\n",
      "Starting on Bedford at 2023-07-05 18:38:30...\n",
      "Starting on Topsfield at 2023-07-05 18:40:58...\n",
      "Starting on Revere at 2023-07-05 18:42:36...\n",
      "Starting on Hull at 2023-07-05 18:51:21...\n",
      "Starting on Malden at 2023-07-05 18:54:00...\n"
     ]
    }
   ],
   "source": [
    "#run parcel based model for each muni in MAPC\n",
    "\n",
    "from src.data.make_dataset import munis\n",
    "\n",
    "processed_path = \"K:\\\\DataServices\\\\Projects\\\\Current_Projects\\\\Environment\\\\MS4\\\\Data\\\\Spatial\\\\Output\\\\Parcels\"\n",
    "\n",
    "'''for town_name in munis['municipal'].unique():\n",
    "    parcel_ms4_model(town_name, processed_path)\n",
    " \n",
    "'''\n",
    "\n",
    "#run suitability model for each town in list\n",
    "for town_name in munis['municipal'].unique():\n",
    "    if town_name in os.listdir(processed_path): #set to skip any towns for which data has already been produced\n",
    "        pass\n",
    "    else:\n",
    "        parcel_ms4_model(town_name, processed_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE SHAPEFILES \n",
    "from src.data.make_dataset import munis\n",
    "\n",
    "model_path = \"K:\\\\DataServices\\\\Projects\\\\Current_Projects\\\\Environment\\\\MS4\\\\Data\\\\Spatial\\\\Model\"\n",
    "\n",
    "filelist = []\n",
    "\n",
    "# add all shapefiles - takes about 30 minutes\n",
    "for root, folder, files in os.walk(processed_path):\n",
    "    for file in files:\n",
    "        for muni in munis['municipal'].unique():\n",
    "            if muni in file:\n",
    "                if file.endswith('.shp'):\n",
    "                    fullname = os.path.join(root, file)\n",
    "                    filelist.append(fullname)\n",
    "\n",
    "\n",
    "merged_gdf = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in filelist], \n",
    "                        ignore_index=True), crs=gpd.read_file(filelist[0]).crs)\n",
    "\n",
    "#export\n",
    "merged_gdf.to_file(model_path + '\\\\Merged_MS4_Parcels.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting on Boston at 2023-07-04 11:27:08...\n",
      "getting row data from Boston\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 7783 entries, 0 to 7782\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count  Dtype   \n",
      "---  ------                  --------------  -----   \n",
      " 0   parloc_id               7783 non-null   int64   \n",
      " 1   FID_Bos_InterBuff_Clip  7783 non-null   int64   \n",
      " 2   FID_Bos_ROWparcels      7783 non-null   int64   \n",
      " 3   ORIG_FID                7783 non-null   int64   \n",
      " 4   Shape_Length            7783 non-null   float64 \n",
      " 5   Shape_Area              7783 non-null   float64 \n",
      " 6   geometry                7783 non-null   geometry\n",
      "dtypes: float64(2), geometry(1), int64(4)\n",
      "memory usage: 486.4 KB\n",
      "None\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "Int64Index: 7783 entries, 0 to 7782\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   parloc_id  7783 non-null   object  \n",
      " 1   geometry   7783 non-null   geometry\n",
      "dtypes: geometry(1), object(1)\n",
      "memory usage: 182.4+ KB\n",
      "None\n",
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 7783 entries, 0 to 7782\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype   \n",
      "---  ------     --------------  -----   \n",
      " 0   parloc_id  7783 non-null   object  \n",
      " 1   type       7783 non-null   object  \n",
      " 2   muni       7783 non-null   object  \n",
      " 3   Owner      7783 non-null   object  \n",
      " 4   Address    7415 non-null   object  \n",
      " 5   acreage    7783 non-null   float64 \n",
      " 6   geometry   7783 non-null   geometry\n",
      "dtypes: float64(1), geometry(1), object(5)\n",
      "memory usage: 425.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from src.features.parcel_model import parcel_ms4_model\n",
    "\n",
    "#rerun for a single muni and then replace those parcels in the old model with the new one\n",
    "processed_path = \"K:\\\\DataServices\\\\Projects\\\\Current_Projects\\\\Environment\\\\MS4\\\\Data\\\\Spatial\\\\Output\\\\Parcels\"\n",
    "muni_sites = parcel_ms4_model('Boston', processed_path)\n",
    "\n",
    "from src.data.make_dataset import munis\n",
    "\n",
    "model_path = \"K:\\\\DataServices\\\\Projects\\\\Current_Projects\\\\Environment\\\\MS4\\\\Data\\\\Spatial\\\\Model\"\n",
    "\n",
    "filelist = []\n",
    "\n",
    "# add all shapefiles - takes about 30 minutes\n",
    "for root, folder, files in os.walk(processed_path):\n",
    "    for file in files:\n",
    "        for muni in munis['municipal'].unique():\n",
    "            if muni in file:\n",
    "                if file.endswith('.shp'):\n",
    "                    fullname = os.path.join(root, file)\n",
    "                    filelist.append(fullname)\n",
    "\n",
    "\n",
    "merged_gdf = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in filelist], \n",
    "                        ignore_index=True), crs=gpd.read_file(filelist[0]).crs)\n",
    "\n",
    "#export\n",
    "merged_gdf.to_file(model_path + '\\\\Merged_MS4_Parcels.shp')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify muni/munis of interest, create a shapefile for the muni\n",
    "\n",
    "Then create land use and land cover layers of interest based on the municipal boundary mask (speeds up processes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull base geographies for analysis\n",
    "- Get municipal ROW and fishnet (tesselation) layers from geodatabases \n",
    "- Clean up those gdfs to include only the relevant info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`town_parcels_row` and `town_tess` are the two base geographies for this analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS-geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
