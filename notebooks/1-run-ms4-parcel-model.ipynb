{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the python model for MAPC's Equitable Green Stormwater Infrastructure Site Selection tool\n",
    "\n",
    "This notebook is meant for running the \"parcel ms4 model\" developed for MAPC's Equitable Green Infrastructure Site Selection Tool. Data inputs can be swapped out at src > data > make_dataset.py. See GitBook documentation for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages \n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols \n",
    "from rasterstats import zonal_stats\n",
    "import rasterio\n",
    "import contextily as cx\n",
    "from rasterio.plot import show\n",
    "#import osmnx as ox\n",
    "from affine import Affine\n",
    "import rioxarray as rx\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from shapely.ops import unary_union\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import fiona\n",
    "\n",
    "#see all columns in tables\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import parcel model function \n",
    "from src.features.parcel_model import parcel_ms4_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run parcel based model for each muni in MAPC\n",
    "\n",
    "from src.data.make_dataset import munis\n",
    "\n",
    "processed_path = \"K:\\\\DataServices\\\\Projects\\\\Current_Projects\\\\Environment\\\\MS4\\\\Data\\\\Spatial\\\\Output\\\\Parcels\"\n",
    "\n",
    "'''for town_name in munis['municipal'].unique():\n",
    "    parcel_ms4_model(town_name, processed_path)\n",
    " \n",
    "'''\n",
    "\n",
    "#run suitability model for each town in list\n",
    "for town_name in munis['municipal'].unique():\n",
    "    if town_name in os.listdir(processed_path): #set to skip any towns for which data has already been produced\n",
    "        pass\n",
    "    else:\n",
    "        parcel_ms4_model(town_name, processed_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE SHAPEFILES \n",
    "from src.data.make_dataset import munis\n",
    "\n",
    "model_path = \"K:\\\\DataServices\\\\Projects\\\\Current_Projects\\\\Environment\\\\MS4\\\\Data\\\\Spatial\\\\Model\"\n",
    "\n",
    "filelist = []\n",
    "\n",
    "# add all shapefiles - takes about 30 minutes\n",
    "for root, folder, files in os.walk(processed_path):\n",
    "    for file in files:\n",
    "        for muni in munis['municipal'].unique():\n",
    "            if muni in file:\n",
    "                if file.endswith('.shp'):\n",
    "                    fullname = os.path.join(root, file)\n",
    "                    filelist.append(fullname)\n",
    "\n",
    "\n",
    "merged_gdf = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in filelist], \n",
    "                        ignore_index=True), crs=gpd.read_file(filelist[0]).crs)\n",
    "\n",
    "#export\n",
    "merged_gdf.to_file(model_path + '\\\\Merged_MS4_Parcels.shp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If some (but not all) municipalities need to be updated, recommend running the script below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rerun for a single muni and then replace those parcels in the old model with the new one\n",
    "\n",
    "from src.features.parcel_model import parcel_ms4_model\n",
    "from src.data.make_dataset import munis\n",
    "\n",
    "\n",
    "processed_path = \"K:\\\\DataServices\\\\Projects\\\\Current_Projects\\\\Environment\\\\MS4\\\\Data\\\\Spatial\\\\Output\\\\Parcels\"\n",
    "model_path = \"K:\\\\DataServices\\\\Projects\\\\Current_Projects\\\\Environment\\\\MS4\\\\Data\\\\Spatial\\\\Model\"\n",
    "\n",
    "\n",
    "#list one or more munis\n",
    "update_munis = ['Boston', 'Bolton']\n",
    "\n",
    "#run script\n",
    "\n",
    "for municipality in update_munis:\n",
    "    parcel_ms4_model(municipality, processed_path)\n",
    "\n",
    "\n",
    "#rejoin all municipalities in \"processed_path\"\n",
    "filelist = []\n",
    "\n",
    "# add all shapefiles - takes about 30 minutes\n",
    "for root, folder, files in os.walk(processed_path):\n",
    "    for file in files:\n",
    "        for muni in munis['municipal'].unique():\n",
    "            if muni in file:\n",
    "                if file.endswith('.shp'):\n",
    "                    fullname = os.path.join(root, file)\n",
    "                    filelist.append(fullname)\n",
    "\n",
    "\n",
    "merged_gdf = gpd.GeoDataFrame(pd.concat([gpd.read_file(i) for i in filelist], \n",
    "                        ignore_index=True), crs=gpd.read_file(filelist[0]).crs)\n",
    "\n",
    "#export\n",
    "merged_gdf.to_file(model_path + '\\\\Merged_MS4_Parcels.shp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb = 'K:\\\\DataServices\\\\Projects\\\\Current_Projects\\\\Environment\\\\MS4\\\\Project\\\\ROW_model_output.gdb'\n",
    "bolton = gpd.read_file(gdb, layer = 'ROW_segmentation_Bolton')\n",
    "bolton.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS-geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
